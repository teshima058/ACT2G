# ACT2G: Attention-based Text-to-Gesture Generation

This repository contains the code of our paper

*ACT2G: Attention-based Contrastive Learning for Text-to-Gesture Generation (SCA 2023)*

* The code and its descriptions will be added soon.

## Citation 

If our code or dataset is helpful, please kindly cite the following paper:
```
@INPROCEEDINGS{
  teshimaSCA2023,
  title={ACT2G: Attention-based Contrastive Learning for Text-to-Gesture Generation},
  author={Hitoshi Teshima, Naoki Wake, Diego Thomas, Yuta Nakashima, Hiroshi Kawasaki and Katsushi Ikeuchi},
  booktitle={The 22nd ACM SIGGRAPH/Eurographics Symposium on Computer Animation(SCA)},
  year={2023}
}
```
